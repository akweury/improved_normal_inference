% Chapter Template

\chapter{Related Work} % Main chapter title

\label{ch:02} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}


Due to the different of data structures, the point clouds can be grouped into types, structured point cloud based and unstructured point cloud based. The first case contains the neighbor information of each point together with a depth map or RGB image, the second case does not contain any neighbor information which has to be further calculated.

\paragraph{ Structured Point Cloud Based}
The relevant methods derive the surface normals based on spatial relationship, which utilizes the neighbor information for estimation. These methods performs well with a well-chosen window size. However, the drawbacks are that the algorithm is highly noise sensitive. It is weak in handling missing pixels, which is a common issue in the input data. The earlier methods usually use optimized methods. \cite{Holzer.S} proposed method to use local neighbors with an interest parameter $ p $ and compute the eigenvectors of the corresponding covariance matrix. They also smooth the depth data in order to handle the noise of depth image. The drawbacks are, as mentioned in the paper, the normals error go up when point depths change severely.  \cite{optimized-methods} did a comparison among the optimization-based methods. 


\paragraph{Unstructured Point Cloud Based}
For the unstructured point cloud, the neighbor information of each point is usually unknown. K-nearest neighbor (KNN) is a common algorithm for neighbor searching. With knowing this information, the neighbor based approaches can be used as a second step. However, KNN-method merely based on the Euclidean distance in the 3D space. Therefore, the points of the other surfaces but in a close distance will also be considered as neighbors. To ease this problem, \cite{unstructed-pc} proposed a method based on unstructured point cloud with selecting the optimal scale around each point for normal estimation. To calculate the normals of multiple points in parallel \cite{unstructed-pc-patch-stitching} processes a series of overlapping patches for normal estimation. 



Deep learning based methods take single RGB image or RGB-D image as the input for normal estimation. It has a strong relationship with the depth inference tasks, two benchmarks are highly used in these area. (\cite{nyu} and \cite{kitti-depth}) Based on the input of training model, the methods can be roughly divided as follows: 

\paragraph{Depth Based}
Depth map contains the spatial information of the object surface, which is very important for the normal inference task. However, the depth map captured by depth sensors are usually with missing pixels and holes on dark, shinny or transparent regions.(\cite{nyu}). To overcome the missing pixels,
\cite{depth-inpainting-distribution} proposed a depth hole filling method using the depth distributions of neighboring regions.  \cite{nconv} introduced normalized convolution dealing with missing or uncertain data for convolution operation. It uses a binary mask to distinguish missing data and integrate it into the convolution operation. \cite{ncnn} applied it and use normalized convolution layers in their networks, which aims to reconstruct the missing pixels from the sparse depth map sensed by cameras. \cite{pncnn} proposed an input confidence estimation network to estimate the confidence instead of using a binary mask. However, the relevant papers are only using 1 channel data as model input, which didn't discussed the case for the multiple-channel data as input, such as RGB image, or structured point cloud.
\cite{depth-enhance-guided} further integrated RGB image as the guidance to deal with the missing pixels in the depth map. 


\paragraph{RGB based} RGB based methods predict the depth map diretly from single RGB image.
\cite{Eigen} proposed a two staged network for depth map prediction based on RGB image, which consider the global features and the local features respectively. \cite{img2depth} employed Residual Network for the feature extraction and further designed a upsampling part which replace the fully-connected layer with the unpolling layers. 
\cite{geometry_based_solution} proposed a method to learn discriminative and geometrically informative primitives from RGBD images, which is further used to recover the surface normals of a scene from a single image. 
\cite{GeoNet} uses ResNet (\cite{resnet}) to infer a coarse surface normal based on RGB image, and further refine it with the help of depth map based on the methods based on \cite{geometry_based_solution}. \cite{binsformer} proposed a method achieved state of art in NYUv2 Dataset (\cite{nyu}), which adaptively generate information to predict depth maps based on RGB image.

\paragraph{RGB-D based}
\cite{hfm} based on UNet architecture for normal estimation using RGB-D image as input. The RGB image and depth map are in the separate branches and imply a fusion module in four sections of the network to concatenate two branches. It also considers the confidence of the values in depth map.












