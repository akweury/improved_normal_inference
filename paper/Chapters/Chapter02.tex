% Chapter Template

\chapter{Related Work} % Main chapter title

\label{ch:02} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}




%% depth map approach
Surface normal inference is a widely researched topic and can be solved in multiple directions. Based on a structured point cloud, the surface normal can be derived from geometry information of the point cloud, which mainly utilizes the neighbor information and consider it as an optimization problem (\cite{optimized-methods} ). They can perform well on dense point cloud input data based on a well-chosen window size. However, the drawbacks are that the algorithms are highly noise sensitive. 
The point cloud is usually not fully dense and normally converted from depth map, which are usually with missing pixels and holes on dark, shinny or transparent regions (\cite{nyu}). The missing points destabilizes the geometry based solution. To ease this problem, \cite{Holzer.S} proposed method to use local neighbors with an interest parameter $ p $ and compute the eigenvectors of the corresponding covariance matrix, which is used to smooth the depth data in order to handle the noise of depth image.  \cite{depth-inpainting-distribution} proposed an approach considers the depth distributions of neighboring regions to fill the holes in the depth map. 
Some approaches use deep learning method to fill missing areas. \cite{nconv} introduces normalized convolution to deal with missing or uncertain depth data with an added mask on the standard convolution operation. \cite{ncnn} applied it and use it as normalized convolution layers in their networks, which aims to reconstruct the missing pixels from the sparse depth map sensed by cameras. \cite{pncnn} proposed an input confidence estimation network to estimate the confidence instead of using a binary mask.


%% photometric approach
Photometric stereo is another approach that infer surface normal from BRDF based surface model. The surface normal is related with observed intensity, the incoming light direction, the outgoing viewing direction and the light intensity. It required multiple light conditions to get an optimal solution. 







%% fusion approach


%% talk about gated convolution, Unet

%% in summary

\paragraph{Unstructured Point Cloud Based}
For the unstructured point cloud, the neighbor information of each point is usually unknown. K-nearest neighbor (KNN) is a common algorithm for neighbor searching. With knowing this information, the neighbor based approaches can be used as a second step. However, KNN-method merely based on the Euclidean distance in the 3D space. Therefore, the points of the other surfaces but in a close distance will also be considered as neighbors. To ease this problem, \cite{unstructed-pc} proposed a method based on unstructured point cloud with selecting the optimal scale around each point for normal estimation. To calculate the normals of multiple points in parallel \cite{unstructed-pc-patch-stitching} processes a series of overlapping patches for normal estimation. 



Deep learning based methods take single RGB image or RGB-D image as the input for normal estimation. It has a strong relationship with the depth inference tasks, two benchmarks are highly used in these area. (\cite{nyu} and \cite{kitti-depth}) Based on the input of training model, the methods can be roughly divided as follows: 



\paragraph{RGB based} RGB based methods predict the depth map diretly from single RGB image.
\cite{Eigen} proposed a two staged network for depth map prediction based on RGB image, which consider the global features and the local features respectively. \cite{img2depth} employed Residual Network for the feature extraction and further designed a upsampling part which replace the fully-connected layer with the unpolling layers. 
\cite{geometry_based_solution} proposed a method to learn discriminative and geometrically informative primitives from RGBD images, which is further used to recover the surface normals of a scene from a single image. 
\cite{GeoNet} uses ResNet (\cite{resnet}) to infer a coarse surface normal based on RGB image, and further refine it with the help of depth map based on the methods based on \cite{geometry_based_solution}. \cite{binsformer} proposed a method achieved state of art in NYUv2 Dataset (\cite{nyu}), which adaptively generate information to predict depth maps based on RGB image.

\paragraph{RGB-D based}
\cite{hfm} based on UNet architecture for normal estimation using RGB-D image as input. The RGB image and depth map are in the separate branches and imply a fusion module in four sections of the network to concatenate two branches. It also considers the confidence of the values in depth map.

\cite{depth-enhance-guided} further integrated RGB image as the guidance to deal with the missing pixels in the depth map. 








