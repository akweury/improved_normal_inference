
%%%%%%%%%%%%%%%%%%% talk about the reason of this thesis %%%%%%%%%%%%%%%%%%

%% standard method for normal inference is insufficient, input is sparse, not robust enough
Standard methods compute normals from point cloud using neighboring information in image space or use Shape from Shading. However, the point clouds captured by sensors like Kinect or similar RGB-D, LiDAR sensors are only semi-dense. As shown in Figure \ref{fig:standard_normal_inference}. If map these normals to mesh, that is not good at all. Standard methods dependents on chosen neighbor size, if too small, it has larger noise sensitive, if too large, the output will too smooth and not crispy. Errors may occur in regions with inter-reflections, where we have errors in the 3D measurement. 

%% add noise image
\begin{figure}[!h]
	\centering
	\begin{tikzpicture}

		
		\node[inner sep=0pt] (depthmap) at (0,0)
		{\includegraphics[width=.3\textwidth]{./pic/00028.depth0.png}};
		
		\path [line] (3,0) -- node [text width=1.5cm,midway,above ] {SVD/PCA} (5,0);
		
		\node[inner sep=0pt] (normal) at (8,0)
		{\includegraphics[width=.3\textwidth]{./pic/00028.normal0.png}};
	\end{tikzpicture}
\caption{Left: Depth Map, Right: Semi-dense Normal Map}
\label{fig:standard_normal_inference}
\end{figure}

%% there exists space for improvment 
Although the depth image is incomplete, the depth sensor usually able to capture grayscale texture image, which are typically fully dense due to their passive nature. Furthermore, if the texture image is already illuminated by strong directional light of a video projector, whose position is known, then there should exist theoretical relations between light direction, normal direction, etc. Thus the normal can be inferenced better using the given image information and depth map. 

%%%%%%%%%%%%%%%%%%% talk about the chanllege of this task %%%%%%%%%%%%%%%%%%
Both depth and grayscale image are initially relevant to the machine learning algorithms. Based grayscale image and corresponding semi-dense depth map, a CNN model can be designed to inference the normal map, which gives more density and robust comparing to standard algorithm. However, the missing pixels in depth map can be distributed around the whole image, some of the region leaves complete empty pixels. This situation imposes further processing for the missing regions and some other challenges on the machine learning methods. 
In this thesis, we found a solution for the problems mentioned above.

%% CNN based methods
The deep convolutional neural network is typically used for image classification, which achieved great success in last several years. \cite{yolov3}, \cite{efficientDet}. 
%% talk about the reason we need new type of network architecture
These kinds of network architecture takes a single image as input which usually employed for classification problems. The image is usually convoluted with convolutional layer and downsampling with pooling layers. The outputs of the network consists of a single value to represent the ID of corresponding class \cite{efficientDet}, or with set of values to represent the position of bounding boxes.\cite{yolov3}.


However, in many other vision tasks, the output is demanded as an image, instead of predicting one or several classes of the input, but the classes of each pixel are predicted. In this case, the traditional network architecture is not suitable anymore.

%% improved normal inference figure
\begin{figure}[!h]
	\centering
	\begin{tikzpicture}
		
		\node[inner sep=0pt] (image) at (0,0)
		{\includegraphics[width=.2\textwidth]{./pic/00028.image0.png}};
		
		\node[text width=1cm] at (2,0) {$ + $};
		
		\node[inner sep=0pt] (depthmap) at (3.3,0)
		{\includegraphics[width=.2\textwidth]{./pic/00028.depth0.png}};
		\node[text width=1cm] at (8,0) {$ ? $};
		
		\path [line] (5,0) -- node [text width=1cm,midway,above ] {CNN} (6,0);
		
	\end{tikzpicture}
	\caption{Left: Grayscale Image, Middle: Depth Map}
	\label{fig:improved_normal_inference}
\end{figure}























